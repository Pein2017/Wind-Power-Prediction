{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","\n","data_dir = \"/data3/lsf/Pein/Power-Prediction/data\"\n","\n","train_input_path = os.path.join(data_dir, \"train_input_merge.csv\")\n","train_power_path = os.path.join(data_dir, \"train_power_merge.csv\")\n","\n","test_input_path = os.path.join(data_dir, \"test_input_merge.csv\")\n","test_power_path = os.path.join(data_dir, \"test_power_merge.csv\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["train_input_ori = pd.read_csv(train_input_path)\n","train_power_ori = pd.read_csv(train_power_path)\n","test_input_ori = pd.read_csv(test_input_path)\n","test_power_ori = pd.read_csv(test_power_path)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Drop the 'initial_time' column\n","train_input_ori = train_input_ori.drop(columns=[\"initial_time\"])\n","test_input_ori = test_input_ori.drop(columns=[\"initial_time\"])\n","\n","# Merge the input and power dataframes on the 'time' column\n","train_data = pd.merge(train_input_ori, train_power_ori, on=\"time\")\n","test_data = pd.merge(test_input_ori, test_power_ori, on=\"time\")"]},{"cell_type":"markdown","metadata":{},"source":["### Conduct a simple clearning\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Ensure 'power' is non-zero, setting negative values to 0\n","train_data[\"power\"] = train_data[\"power\"].apply(lambda x: max(x, 0))\n","test_data[\"power\"] = test_data[\"power\"].apply(lambda x: max(x, 0))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","0\n","0\n","0\n"]}],"source":["# Check the nan values in the dataset\n","print(train_data.isnull().sum().sum())\n","print(test_data.isnull().sum().sum())\n","\n","# check all the 'power' is non-negative\n","print(train_data[train_data[\"power\"] < 0].shape[0])\n","print(test_data[test_data[\"power\"] < 0].shape[0])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["For train: 14592 vs 14592\n","For test: 2880 vs 2880\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1705223/1235129531.py:4: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  train_date_range = pd.date_range(\n","/tmp/ipykernel_1705223/1235129531.py:8: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n","  test_date_range = pd.date_range(\n"]}],"source":["n_train = len(train_data[\"time\"])\n","n_test = len(test_data[\"time\"])\n","\n","train_date_range = pd.date_range(\n","    start=train_data.time.min(), end=train_data.time.max(), freq=\"15T\"\n",")\n","\n","test_date_range = pd.date_range(\n","    start=test_data.time.min(), end=test_data.time.max(), freq=\"15T\"\n",")\n","\n","print(f\"For train: {n_train} vs {len(train_date_range)}\")\n","print(f\"For test: {n_test} vs {len(test_date_range)}\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Ignore 'time' and 'lead_hour' for cleaning\n","ignore_features = [\"time\", \"lead_hour\"]\n","features = [col for col in train_data.columns if col not in ignore_features + [\"power\"]]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Select features with small variance\n","from sklearn.feature_selection import VarianceThreshold\n","\n","# Step 1: Variance Threshold Filtering\n","selector = VarianceThreshold(threshold=0.1)  # Adjust the threshold as needed\n","train_data_variance_filtered = selector.fit_transform(train_data[features])\n","selected_variance_features = train_data[features].columns[selector.get_support()]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Create new train and test data with selected features\n","train_data = train_data[\n","    ignore_features + selected_variance_features.tolist() + [\"power\"]\n","]\n","test_data = test_data[ignore_features + selected_variance_features.tolist() + [\"power\"]]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected Features has 89:\n"," Index(['altitude', 'azimuth', 'u100', 'v100', 'fg10', 'u10', 'v10', 'u200',\n","       'v200', 'd2m', 't2m', 'bld', 'blh', 'cape', 'capes', 'cdir', 'deg0l',\n","       'degm10l', 'dsrp', 'ewss', 'fdir', 'flsr', 'gwd', 'hcc', 'hwbt0',\n","       'hwbt1', 'i10fg', 'ilspf', 'ishf', 'kx', 'lblt', 'lcc', 'lgws',\n","       'litoti', 'lmlt', 'lspf', 'ltlt', 'mcc', 'mgws', 'mlcape100',\n","       'mlcape50', 'mld', 'mn2t', 'msl', 'mucape', 'mudlp', 'mx2t', 'nsss',\n","       'parcs', 'par', 'totalx', 'skt', 'slhf', 'sp', 'sshf', 'ssrc', 'ssrdc',\n","       'ssrd', 'ssr', 'sst', 'stl1', 'stl2', 'stl3', 'stl4', 'strc', 'strdc',\n","       'strd', 'str', 'sund', 'tcc', 'tcsw', 'tcw', 'tcwv', 'tisr', 'trpp',\n","       'tsrc', 'tsr', 'ttrc', 'ttr', 'u10n', 'uvb', 'v10n', 'vimd', 'p3020',\n","       'viwve', 'viwvn', 'ws200', 'ws100', 'ws10'],\n","      dtype='object')\n","Total num of feature is 92\n"]}],"source":["print(\n","    f\"Selected Features has {len(selected_variance_features)}:\\n\",\n","    selected_variance_features,\n",")\n","print(f\"Total num of feature is {len(train_data.columns)}\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Combined train and test datasets have been saved to 'train_data.csv' and 'test_data.csv'.\n"]}],"source":["# Save the combined datasets to CSV files\n","train_data.to_csv(f\"{data_dir}/\" + \"train_data_92.csv\", index=False)\n","test_data.to_csv(f\"{data_dir}/\" + \"test_data_92.csv\", index=False)\n","\n","print(\n","    \"Combined train and test datasets have been saved to 'train_data.csv' and 'test_data.csv'.\"\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from prepare_data import WindPowerDataset\n","\n","data_dir = \"/data3/lsf/Pein/Power-Prediction/data\"\n","train_ori = os.path.join(data_dir, \"train_data.csv\")\n","test_ori = os.path.join(data_dir, \"test_data.csv\")\n","\n","# Parameters\n","seq_len = 2  # example sequence length\n","\n","# Create datasets\n","train_dataset = WindPowerDataset(train_ori, seq_len)\n","test_dataset = WindPowerDataset(test_ori, seq_len)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'DataFrame' object is not callable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Pein_310","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}
