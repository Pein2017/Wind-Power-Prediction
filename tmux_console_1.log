[I 2024-08-08 16:54:03,987] Using an existing study with name '24-08-08-farm_65-simpleLSTM-test' instead of creating a new one.
Creating study "24-08-08-farm_65-simpleLSTM-test" with storage "sqlite:////data3/lsf/Pein/Power-Prediction/optuna_results/24-08-08/24-08-08-farm_65-simpleLSTM-test.db"...
Not using pruner
  0%|          | 0/10 [00:00<?, ?it/s]Seed set to 17
/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data3/lsf/Pein/Power-Prediction/run_scripts/run_opt ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]

  | Name      | Type    | Params | Mode 
----------------------------------------------
0 | model     | Model   | 557 K  | train
1 | criterion | MSELoss | 0      | train
----------------------------------------------
557 K     Trainable params
0         Non-trainable params
557 K     Total params
2.231     Total estimated model params size (MB)
Metric Loss/val improved. New best score: 2.172
Metric Loss/val improved by 0.834 >= min_delta = 0.0. New best score: 1.338
Metric Loss/val improved by 0.040 >= min_delta = 0.0. New best score: 1.299
Metric Loss/val improved by 0.102 >= min_delta = 0.0. New best score: 1.197
Metric Loss/val improved by 0.094 >= min_delta = 0.0. New best score: 1.103
Metric Loss/val improved by 0.097 >= min_delta = 0.0. New best score: 1.006
Monitored metric Loss/val did not improve in the last 15 records. Best score: 1.006. Signaling Trainer to stop.
                                        0%|          | 0/10 [02:31<?, ?it/s]Best trial: 0. Best value: 0.889153:   0%|          | 0/10 [02:31<?, ?it/s]Best trial: 0. Best value: 0.889153:  10%|█         | 1/10 [02:31<22:47, 151.94s/it]Seed set to 17
/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data3/lsf/Pein/Power-Prediction/run_scripts/run_opt ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]

  | Name      | Type    | Params | Mode 
----------------------------------------------
0 | model     | Model   | 361 K  | train
1 | criterion | MSELoss | 0      | train
----------------------------------------------
361 K     Trainable params
0         Non-trainable params
361 K     Total params
1.445     Total estimated model params size (MB)
Metric Loss/val improved. New best score: 1.645
Metric Loss/val improved by 0.185 >= min_delta = 0.0. New best score: 1.460
Metric Loss/val improved by 0.317 >= min_delta = 0.0. New best score: 1.143
Monitored metric Loss/val did not improve in the last 15 records. Best score: 1.143. Signaling Trainer to stop.
                                                                                    Best trial: 0. Best value: 0.889153:  10%|█         | 1/10 [04:04<22:47, 151.94s/it]Best trial: 0. Best value: 0.889153:  10%|█         | 1/10 [04:04<22:47, 151.94s/it]Best trial: 0. Best value: 0.889153:  20%|██        | 2/10 [04:04<15:37, 117.22s/it]Base config keys: dict_keys(['general_settings', 'output_paths', 'data_paths', 'data_settings', 'model_settings', 'exp_settings', 'training_settings', 'scheduler_settings', 'gpu_settings', 'additional_settings', 'logging_settings'])
Suggested hyperparameters keys: dict_keys(['d_model', 'hidden_dim', 'token_conv_kernel', 'last_hidden_dim', 'time_d_model', 'e_layers', 'learning_rate', 'batch_size', 'train_epochs', 'seq_len', 'dropout', 'combine_type', 'use_pos_enc', 'norm_type', 'num_heads'])

Running experiment with config:
Namespace(general_settings=Namespace(seed=17, is_training=1, task_name='default', description='train', comment='optuna search'), output_paths=Namespace(train_log_dir='/data3/lsf/Pein/Power-Prediction/train_log/24-08-08', res_output_dir='/data3/lsf/Pein/Power-Prediction/res_output/24-08-08', final_best_metrics_log_path='/data3/lsf/Pein/Power-Prediction/final_best_metric/24-08-08.log', optuna_study_dir='/data3/lsf/Pein/Power-Prediction/optuna_study/24-08-08', wandb_output_dir='/data3/lsf/Pein/Power-Prediction/wandb_output/optuna/24-08-08'), data_paths=Namespace(data_root_dir='/data3/lsf/Pein/Power-Prediction/data', train_path='train_farm_65_withTime.csv', test_path='test_farm_65_withTime.csv'), data_settings=Namespace(train_val_split=0.2, target='power', inverse=True, num_workers=8, data='WindPower', scale_x_type='standard', scale_y_type='standard'), model_settings=Namespace(name='SimpleTransformer', token_conv_kernel=9, input_dim=51, dec_in=51, output_dim=1, d_model=4, n_heads=4, e_layers=2, hidden_dim=256, seq_layers=2, last_hidden_dim=1024, top_k=5, num_kernels=6, activation='gelu', time_d_model=3, combine_type='add', seq_len=16, pred_len=1, min_y_value=0.0, dropout=0.2, use_pos_enc=False, bidirectional=False, norm_type='batch', num_heads=12), exp_settings='seq_len-16-lr-0.01-d-4-hid_d-256-last_d-1024-time_d-3-e_layers-2-tok_conv_k-9-dropout-0.2-bs-256-norm_type-batch', training_settings=Namespace(gradient_clip_val=1, train_epochs=40, batch_size=256, early_stop_patience=15, learning_rate=0.01, loss='MSE', lradj='TST', pct_start=0.3, use_amp=False, moving_avg=51, decomp_method='moving_avg', use_norm=1, down_sampling_layers=2, down_sampling_window=2, down_sampling_method='avg'), scheduler_settings=Namespace(type='OneCycleLR', T_max=20, weight_decay=0.0001, patience=5, reduce_factor=0.2, pct_start=0.3, eta_min='1e-6', warmup_steps=0), gpu_settings=Namespace(use_gpu=True, gpu_id=0, use_multi_gpu=False, use_all_gpus_for_search=False), additional_settings=None, logging_settings=Namespace(use_wandb=False))


******************************
Data shapes:
Train X shape: (11673, 51)
Train y shape: (11673, 1)
Val X shape: (2919, 51)
Val y shape: (2919, 1)
Test X shape: (2880, 51)
Test y shape: (2880, 1)
Train X mark shape: (11673, 12)
Val X mark shape: (2919, 12)
Test X mark shape: (2880, 12)
******************************
[I 2024-08-08 16:56:35,918] Trial 1 finished with value: 0.9166155397892 and parameters: {'d_model': 4, 'hidden_dim': 256, 'token_conv_kernel': 9, 'last_hidden_dim': 1024, 'time_d_model': 3, 'e_layers': 2, 'learning_rate': 0.01, 'batch_size': 256, 'train_epochs': 40, 'seq_len': 16, 'dropout': 0.2, 'combine_type': 'add', 'use_pos_enc': False, 'norm_type': 'batch', 'num_heads': 12}. Best is trial 0 with value: 0.8891527116298676.
Base config keys: dict_keys(['general_settings', 'output_paths', 'data_paths', 'data_settings', 'model_settings', 'exp_settings', 'training_settings', 'scheduler_settings', 'gpu_settings', 'additional_settings', 'logging_settings'])
Suggested hyperparameters keys: dict_keys(['d_model', 'hidden_dim', 'token_conv_kernel', 'last_hidden_dim', 'time_d_model', 'e_layers', 'learning_rate', 'batch_size', 'train_epochs', 'seq_len', 'dropout', 'combine_type', 'use_pos_enc', 'norm_type', 'num_heads'])

Running experiment with config:
Namespace(general_settings=Namespace(seed=17, is_training=1, task_name='default', description='train', comment='optuna search'), output_paths=Namespace(train_log_dir='/data3/lsf/Pein/Power-Prediction/train_log/24-08-08', res_output_dir='/data3/lsf/Pein/Power-Prediction/res_output/24-08-08', final_best_metrics_log_path='/data3/lsf/Pein/Power-Prediction/final_best_metric/24-08-08.log', optuna_study_dir='/data3/lsf/Pein/Power-Prediction/optuna_study/24-08-08', wandb_output_dir='/data3/lsf/Pein/Power-Prediction/wandb_output/optuna/24-08-08'), data_paths=Namespace(data_root_dir='/data3/lsf/Pein/Power-Prediction/data', train_path='train_farm_65_withTime.csv', test_path='test_farm_65_withTime.csv'), data_settings=Namespace(train_val_split=0.2, target='power', inverse=True, num_workers=8, data='WindPower', scale_x_type='standard', scale_y_type='standard'), model_settings=Namespace(name='SimpleTransformer', token_conv_kernel=9, input_dim=51, dec_in=51, output_dim=1, d_model=4, n_heads=4, e_layers=2, hidden_dim=16, seq_layers=2, last_hidden_dim=1024, top_k=5, num_kernels=6, activation='gelu', time_d_model=3, combine_type='add', seq_len=16, pred_len=1, min_y_value=0.0, dropout=0.2, use_pos_enc=False, bidirectional=False, norm_type='batch', num_heads=12), exp_settings='seq_len-16-lr-0.001-d-4-hid_d-16-last_d-1024-time_d-3-e_layers-2-tok_conv_k-9-dropout-0.2-bs-256-norm_type-batch', training_settings=Namespace(gradient_clip_val=1, train_epochs=40, batch_size=256, early_stop_patience=15, learning_rate=0.001, loss='MSE', lradj='TST', pct_start=0.3, use_amp=False, moving_avg=51, decomp_method='moving_avg', use_norm=1, down_sampling_layers=2, down_sampling_window=2, down_sampling_method='avg'), scheduler_settings=Namespace(type='OneCycleLR', T_max=20, weight_decay=0.0001, patience=5, reduce_factor=0.2, pct_start=0.3, eta_min='1e-6', warmup_steps=0), gpu_settings=Namespace(use_gpu=True, gpu_id=0, use_multi_gpu=False, use_all_gpus_for_search=False), additional_settings=None, logging_settings=Namespace(use_wandb=False))


******************************
Data shapes:
Train X shape: (11673, 51)
Train y shape: (11673, 1)
Val X shape: (2919, 51)
Val y shape: (2919, 1)
Test X shape: (2880, 51)
Test y shape: (2880, 1)
Train X mark shape: (11673, 12)
Val X mark shape: (2919, 12)
Test X mark shape: (2880, 12)
******************************
[I 2024-08-08 16:58:08,830] Trial 3 finished with value: 1.6010445252060892 and parameters: {'d_model': 4, 'hidden_dim': 16, 'token_conv_kernel': 9, 'last_hidden_dim': 1024, 'time_d_model': 3, 'e_layers': 2, 'learning_rate': 0.001, 'batch_size': 256, 'train_epochs': 40, 'seq_len': 16, 'dropout': 0.2, 'combine_type': 'add', 'use_pos_enc': False, 'norm_type': 'batch', 'num_heads': 12}. Best is trial 0 with value: 0.8891527116298676.
Base config keys: dict_keys(['general_settings', 'output_paths', 'data_paths', 'data_settings', 'model_settings', 'exp_settings', 'training_settings', 'scheduler_settings', 'gpu_settings', 'additional_settings', 'logging_settings'])
Suggested hyperparameters keys: dict_keys(['d_model', 'hidden_dim', 'token_conv_kernel', 'last_hidden_dim', 'time_d_model', 'e_layers', 'learning_rate', 'batch_size', 'train_epochs', 'seq_len', 'dropout', 'combine_type', 'use_pos_enc', 'norm_type', 'num_heads'])
Seed set to 17
/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data3/lsf/Pein/Power-Prediction/run_scripts/run_opt ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]

  | Name      | Type    | Params | Mode 
----------------------------------------------
0 | model     | Model   | 14.1 M | train
1 | criterion | MSELoss | 0      | train
----------------------------------------------
14.1 M    Trainable params
0         Non-trainable params
14.1 M    Total params
56.374    Total estimated model params size (MB)
Metric Loss/val improved. New best score: 3.622
Metric Loss/val improved by 0.866 >= min_delta = 0.0. New best score: 2.756
Metric Loss/val improved by 1.243 >= min_delta = 0.0. New best score: 1.513
Metric Loss/val improved by 0.245 >= min_delta = 0.0. New best score: 1.268
Metric Loss/val improved by 0.034 >= min_delta = 0.0. New best score: 1.233
Metric Loss/val improved by 0.003 >= min_delta = 0.0. New best score: 1.230
Metric Loss/val improved by 0.018 >= min_delta = 0.0. New best score: 1.212
Monitored metric Loss/val did not improve in the last 15 records. Best score: 1.212. Signaling Trainer to stop.
                                                                                    Best trial: 0. Best value: 0.889153:  20%|██        | 2/10 [07:32<15:37, 117.22s/it]Best trial: 0. Best value: 0.889153:  20%|██        | 2/10 [07:32<15:37, 117.22s/it]Best trial: 0. Best value: 0.889153:  30%|███       | 3/10 [07:32<18:29, 158.50s/it]Seed set to 17
/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data3/lsf/Pein/Power-Prediction/run_scripts/run_opt ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]

  | Name      | Type    | Params | Mode 
----------------------------------------------
0 | model     | Model   | 374 K  | train
1 | criterion | MSELoss | 0      | train
----------------------------------------------
374 K     Trainable params
0         Non-trainable params
374 K     Total params
1.498     Total estimated model params size (MB)
Metric Loss/val improved. New best score: 0.870
Metric Loss/val improved by 0.090 >= min_delta = 0.0. New best score: 0.781
Metric Loss/val improved by 0.028 >= min_delta = 0.0. New best score: 0.753
Metric Loss/val improved by 0.004 >= min_delta = 0.0. New best score: 0.749
Monitored metric Loss/val did not improve in the last 15 records. Best score: 0.749. Signaling Trainer to stop.
                                                                                    Best trial: 0. Best value: 0.889153:  30%|███       | 3/10 [09:23<18:29, 158.50s/it]Best trial: 5. Best value: 0.768029:  30%|███       | 3/10 [09:23<18:29, 158.50s/it]Best trial: 5. Best value: 0.768029:  40%|████      | 4/10 [09:23<13:58, 139.79s/it]
Running experiment with config:
Namespace(general_settings=Namespace(seed=17, is_training=1, task_name='default', description='train', comment='optuna search'), output_paths=Namespace(train_log_dir='/data3/lsf/Pein/Power-Prediction/train_log/24-08-08', res_output_dir='/data3/lsf/Pein/Power-Prediction/res_output/24-08-08', final_best_metrics_log_path='/data3/lsf/Pein/Power-Prediction/final_best_metric/24-08-08.log', optuna_study_dir='/data3/lsf/Pein/Power-Prediction/optuna_study/24-08-08', wandb_output_dir='/data3/lsf/Pein/Power-Prediction/wandb_output/optuna/24-08-08'), data_paths=Namespace(data_root_dir='/data3/lsf/Pein/Power-Prediction/data', train_path='train_farm_65_withTime.csv', test_path='test_farm_65_withTime.csv'), data_settings=Namespace(train_val_split=0.2, target='power', inverse=True, num_workers=8, data='WindPower', scale_x_type='standard', scale_y_type='standard'), model_settings=Namespace(name='SimpleTransformer', token_conv_kernel=9, input_dim=51, dec_in=51, output_dim=1, d_model=8, n_heads=4, e_layers=16, hidden_dim=256, seq_layers=2, last_hidden_dim=1024, top_k=5, num_kernels=6, activation='gelu', time_d_model=3, combine_type='add', seq_len=16, pred_len=1, min_y_value=0.0, dropout=0.2, use_pos_enc=False, bidirectional=False, norm_type='batch', num_heads=24), exp_settings='seq_len-16-lr-0.01-d-8-hid_d-256-last_d-1024-time_d-3-e_layers-16-tok_conv_k-9-dropout-0.2-bs-256-norm_type-batch', training_settings=Namespace(gradient_clip_val=1, train_epochs=40, batch_size=256, early_stop_patience=15, learning_rate=0.01, loss='MSE', lradj='TST', pct_start=0.3, use_amp=False, moving_avg=51, decomp_method='moving_avg', use_norm=1, down_sampling_layers=2, down_sampling_window=2, down_sampling_method='avg'), scheduler_settings=Namespace(type='OneCycleLR', T_max=20, weight_decay=0.0001, patience=5, reduce_factor=0.2, pct_start=0.3, eta_min='1e-6', warmup_steps=0), gpu_settings=Namespace(use_gpu=True, gpu_id=0, use_multi_gpu=False, use_all_gpus_for_search=False), additional_settings=None, logging_settings=Namespace(use_wandb=False))


******************************
Data shapes:
Train X shape: (11673, 51)
Train y shape: (11673, 1)
Val X shape: (2919, 51)
Val y shape: (2919, 1)
Test X shape: (2880, 51)
Test y shape: (2880, 1)
Train X mark shape: (11673, 12)
Val X mark shape: (2919, 12)
Test X mark shape: (2880, 12)
******************************
[I 2024-08-08 17:01:36,447] Trial 4 finished with value: 1.1067873477935792 and parameters: {'d_model': 8, 'hidden_dim': 256, 'token_conv_kernel': 9, 'last_hidden_dim': 1024, 'time_d_model': 3, 'e_layers': 16, 'learning_rate': 0.01, 'batch_size': 256, 'train_epochs': 40, 'seq_len': 16, 'dropout': 0.2, 'combine_type': 'add', 'use_pos_enc': False, 'norm_type': 'batch', 'num_heads': 24}. Best is trial 0 with value: 0.8891527116298676.
Base config keys: dict_keys(['general_settings', 'output_paths', 'data_paths', 'data_settings', 'model_settings', 'exp_settings', 'training_settings', 'scheduler_settings', 'gpu_settings', 'additional_settings', 'logging_settings'])
Suggested hyperparameters keys: dict_keys(['d_model', 'hidden_dim', 'token_conv_kernel', 'last_hidden_dim', 'time_d_model', 'e_layers', 'learning_rate', 'batch_size', 'train_epochs', 'seq_len', 'dropout', 'combine_type', 'use_pos_enc', 'norm_type', 'num_heads'])

Running experiment with config:
Namespace(general_settings=Namespace(seed=17, is_training=1, task_name='default', description='train', comment='optuna search'), output_paths=Namespace(train_log_dir='/data3/lsf/Pein/Power-Prediction/train_log/24-08-08', res_output_dir='/data3/lsf/Pein/Power-Prediction/res_output/24-08-08', final_best_metrics_log_path='/data3/lsf/Pein/Power-Prediction/final_best_metric/24-08-08.log', optuna_study_dir='/data3/lsf/Pein/Power-Prediction/optuna_study/24-08-08', wandb_output_dir='/data3/lsf/Pein/Power-Prediction/wandb_output/optuna/24-08-08'), data_paths=Namespace(data_root_dir='/data3/lsf/Pein/Power-Prediction/data', train_path='train_farm_65_withTime.csv', test_path='test_farm_65_withTime.csv'), data_settings=Namespace(train_val_split=0.2, target='power', inverse=True, num_workers=8, data='WindPower', scale_x_type='standard', scale_y_type='standard'), model_settings=Namespace(name='SimpleTransformer', token_conv_kernel=9, input_dim=51, dec_in=51, output_dim=1, d_model=4, n_heads=4, e_layers=2, hidden_dim=32, seq_layers=2, last_hidden_dim=1024, top_k=5, num_kernels=6, activation='gelu', time_d_model=3, combine_type='add', seq_len=16, pred_len=1, min_y_value=0.0, dropout=0.2, use_pos_enc=False, bidirectional=False, norm_type='layer', num_heads=12), exp_settings='seq_len-16-lr-0.001-d-4-hid_d-32-last_d-1024-time_d-3-e_layers-2-tok_conv_k-9-dropout-0.2-bs-256-norm_type-layer', training_settings=Namespace(gradient_clip_val=1, train_epochs=40, batch_size=256, early_stop_patience=15, learning_rate=0.001, loss='MSE', lradj='TST', pct_start=0.3, use_amp=False, moving_avg=51, decomp_method='moving_avg', use_norm=1, down_sampling_layers=2, down_sampling_window=2, down_sampling_method='avg'), scheduler_settings=Namespace(type='OneCycleLR', T_max=20, weight_decay=0.0001, patience=5, reduce_factor=0.2, pct_start=0.3, eta_min='1e-6', warmup_steps=0), gpu_settings=Namespace(use_gpu=True, gpu_id=0, use_multi_gpu=False, use_all_gpus_for_search=False), additional_settings=None, logging_settings=Namespace(use_wandb=False))


******************************
Data shapes:
Train X shape: (11673, 51)
Train y shape: (11673, 1)
Val X shape: (2919, 51)
Val y shape: (2919, 1)
Test X shape: (2880, 51)
Test y shape: (2880, 1)
Train X mark shape: (11673, 12)
Val X mark shape: (2919, 12)
Test X mark shape: (2880, 12)
******************************
[I 2024-08-08 17:03:27,565] Trial 5 finished with value: 0.7680294409394265 and parameters: {'d_model': 4, 'hidden_dim': 32, 'token_conv_kernel': 9, 'last_hidden_dim': 1024, 'time_d_model': 3, 'e_layers': 2, 'learning_rate': 0.001, 'batch_size': 256, 'train_epochs': 40, 'seq_len': 16, 'dropout': 0.2, 'combine_type': 'add', 'use_pos_enc': False, 'norm_type': 'layer', 'num_heads': 12}. Best is trial 5 with value: 0.7680294409394265.
Base config keys: dict_keys(['general_settings', 'output_paths', 'data_paths', 'data_settings', 'model_settings', 'exp_settings', 'training_settings', 'scheduler_settings', 'gpu_settings', 'additional_settings', 'logging_settings'])
Suggested hyperparameters keys: dict_keys(['d_model', 'hidden_dim', 'token_conv_kernel', 'last_hidden_dim', 'time_d_model', 'e_layers', 'learning_rate', 'batch_size', 'train_epochs', 'seq_len', 'dropout', 'combine_type', 'use_pos_enc', 'norm_type', 'num_heads'])
Seed set to 17
                                                                                    Best trial: 5. Best value: 0.768029:  40%|████      | 4/10 [09:25<13:58, 139.79s/it]                                                                                    Best trial: 5. Best value: 0.768029:  40%|████      | 4/10 [09:25<13:58, 139.79s/it]Best trial: 5. Best value: 0.768029:  40%|████      | 4/10 [09:25<14:08, 141.42s/it]

Running experiment with config:
Namespace(general_settings=Namespace(seed=17, is_training=1, task_name='default', description='train', comment='optuna search'), output_paths=Namespace(train_log_dir='/data3/lsf/Pein/Power-Prediction/train_log/24-08-08', res_output_dir='/data3/lsf/Pein/Power-Prediction/res_output/24-08-08', final_best_metrics_log_path='/data3/lsf/Pein/Power-Prediction/final_best_metric/24-08-08.log', optuna_study_dir='/data3/lsf/Pein/Power-Prediction/optuna_study/24-08-08', wandb_output_dir='/data3/lsf/Pein/Power-Prediction/wandb_output/optuna/24-08-08'), data_paths=Namespace(data_root_dir='/data3/lsf/Pein/Power-Prediction/data', train_path='train_farm_65_withTime.csv', test_path='test_farm_65_withTime.csv'), data_settings=Namespace(train_val_split=0.2, target='power', inverse=True, num_workers=8, data='WindPower', scale_x_type='standard', scale_y_type='standard'), model_settings=Namespace(name='SimpleTransformer', token_conv_kernel=9, input_dim=51, dec_in=51, output_dim=1, d_model=4, n_heads=4, e_layers=16, hidden_dim=32, seq_layers=2, last_hidden_dim=1024, top_k=5, num_kernels=6, activation='gelu', time_d_model=3, combine_type='add', seq_len=16, pred_len=1, min_y_value=0.0, dropout=0.2, use_pos_enc=False, bidirectional=False, norm_type='layer', num_heads=24), exp_settings='seq_len-16-lr-0.01-d-4-hid_d-32-last_d-1024-time_d-3-e_layers-16-tok_conv_k-9-dropout-0.2-bs-256-norm_type-layer', training_settings=Namespace(gradient_clip_val=1, train_epochs=40, batch_size=256, early_stop_patience=15, learning_rate=0.01, loss='MSE', lradj='TST', pct_start=0.3, use_amp=False, moving_avg=51, decomp_method='moving_avg', use_norm=1, down_sampling_layers=2, down_sampling_window=2, down_sampling_method='avg'), scheduler_settings=Namespace(type='OneCycleLR', T_max=20, weight_decay=0.0001, patience=5, reduce_factor=0.2, pct_start=0.3, eta_min='1e-6', warmup_steps=0), gpu_settings=Namespace(use_gpu=True, gpu_id=0, use_multi_gpu=False, use_all_gpus_for_search=False), additional_settings=None, logging_settings=Namespace(use_wandb=False))


******************************
Data shapes:
Train X shape: (11673, 51)
Train y shape: (11673, 1)
Val X shape: (2919, 51)
Val y shape: (2919, 1)
Test X shape: (2880, 51)
Test y shape: (2880, 1)
Train X mark shape: (11673, 12)
Val X mark shape: (2919, 12)
Test X mark shape: (2880, 12)
******************************
[W 2024-08-08 17:03:29,670] Trial 6 failed with parameters: {'d_model': 4, 'hidden_dim': 32, 'token_conv_kernel': 9, 'last_hidden_dim': 1024, 'time_d_model': 3, 'e_layers': 16, 'learning_rate': 0.01, 'batch_size': 256, 'train_epochs': 40, 'seq_len': 16, 'dropout': 0.2, 'combine_type': 'add', 'use_pos_enc': False, 'norm_type': 'layer', 'num_heads': 24} because of the following error: AssertionError('embed_dim must be divisible by num_heads').
Traceback (most recent call last):
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 393, in <lambda>
    lambda trial: objective(trial, config_path, time_str=time_str),
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 244, in objective
    ) = setup_environment(trial, base_config)
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 58, in setup_environment
    wind_power_module = WindPowerExperiment(args)
  File "/data3/lsf/Pein/Power-Prediction/exp/pl_exp.py", line 35, in __init__
    self.model = self._build_model()
  File "/data3/lsf/Pein/Power-Prediction/exp/pl_exp.py", line 199, in _build_model
    model = self.model_dict[model_settings.name].Model(model_settings).float()
  File "/data3/lsf/Pein/Power-Prediction/models/SimpleTransformer.py", line 117, in __init__
    assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
AssertionError: embed_dim must be divisible by num_heads
[W 2024-08-08 17:03:29,671] Trial 6 failed with value None.
Traceback (most recent call last):
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 499, in <module>
    main()
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 492, in main
    run_optuna_study(args)
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 406, in run_optuna_study
    run_optimization(
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 392, in run_optimization
    study.optimize(
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/home/lsf/anaconda3/envs/Pein_310/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 393, in <lambda>
    lambda trial: objective(trial, config_path, time_str=time_str),
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 244, in objective
    ) = setup_environment(trial, base_config)
  File "/data3/lsf/Pein/Power-Prediction/run_scripts/run_optuna.py", line 58, in setup_environment
    wind_power_module = WindPowerExperiment(args)
  File "/data3/lsf/Pein/Power-Prediction/exp/pl_exp.py", line 35, in __init__
    self.model = self._build_model()
  File "/data3/lsf/Pein/Power-Prediction/exp/pl_exp.py", line 199, in _build_model
    model = self.model_dict[model_settings.name].Model(model_settings).float()
  File "/data3/lsf/Pein/Power-Prediction/models/SimpleTransformer.py", line 117, in __init__
    assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"
AssertionError: embed_dim must be divisible by num_heads
