# General settings
general_settings:
  seed: 17
  is_training: 1
  description: "train"
  comment: "optuna search"

# exp_time_str: 'exp_time_str'

# Output Paths
output_paths:
  train_log_dir: "/data/Pein/Pytorch/Wind-Power-Prediction/train_log/exp_time_str"
  res_output_dir: "/data/Pein/Pytorch/Wind-Power-Prediction/res_output/exp_time_str"
  final_best_metrics_log_path: "/data/Pein/Pytorch/Wind-Power-Prediction/final_best_metric/exp_time_str.log"
  optuna_study_dir: "/data/Pein/Pytorch/Wind-Power-Prediction/optuna_study/exp_time_str"
  wandb_output_dir: "/data/Pein/Pytorch/Wind-Power-Prediction/wandb_output/optuna/exp_time_str"

# Data paths
data_paths:
  data_root_dir: "/data/Pein/Pytorch/Wind-Power-Prediction/new_data/"
  train_path: "4-train_66_withTime.csv"
  test_path: "4-test_66_withTime.csv"

# Data settings
data_settings:
  y_transform_order: 0.333
  val_split : 0.2
  target: "power"
  inverse: true
  num_workers: 4
  data: "WindPower"
  scale_x_type: "standard"
  scale_y_type: "standard"
  random_split: false


# Model settings
model_settings:
  task_name: "wind_power_forecasting with single farm station"
  name: "MLP_v3"
  token_conv_kernel: 3
  input_dim: 52
  dec_in: 52
  output_dim: 1
  d_model: 5
  n_heads: 4
  e_layers: 2
  hidden_d_model: 32
  seq_layers: 2
  last_d_model: 16
  top_k: 5
  num_kernels: 6
  activation_type: "gelu"
  token_d_model: 16
  time_d_model: 16
  pos_d_model: 16
  combine_type: "add"
  seq_len: 8
  pred_len: 1
  min_y_value: 0.0
  dropout: 0.1
  use_pos_enc: true
  bidirectional: false
  norm_type: "batch"
  num_heads: 8
  fc_layer_type: "mlp"
  conv_out_dim: 3
  feat_conv_kernel: 10
  skip_connection_mode: "none"
  conv_norm: null
  mlp_norm: null
  norm_after_dict: null

# Global Settings
exp_settings: null

# Training settings
training_settings:
  gradient_clip_val: 1
  train_epochs: 120
  batch_size: 1100
  early_stop_patience: 15
  learning_rate: 0.01
  loss: "MSE"
  lradj: "TST"
  pct_start: 0.3
  use_amp: false
  moving_avg: 30
  decomp_method: "moving_avg"
  use_norm: 1
  down_sampling_layers: 2
  down_sampling_window: 2
  down_sampling_method: "avg"

# Scheduler settings
scheduler_settings:
  type: "OneCycleLR"
  T_max: 20
  weight_decay: 0.0001
  patience: 5
  reduce_factor: 0.2
  pct_start: 0.3
  eta_min: 1e-6
  warmup_steps: 0

# GPU settings
gpu_settings:
  use_gpu: True
  gpu_id: 0
  use_multi_gpu: False
  use_all_gpus_for_search: False

# Additional settings
additional_settings:

# Logging settings
logging_settings:
  use_wandb: False
