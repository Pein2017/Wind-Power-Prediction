{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # noqa\n",
    "import optuna\n",
    "import time\n",
    "import logging  # noqa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "\n",
    "# Enable logging\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "\n",
    "class TimingCallback:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "        else:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            print(f\"Trial {trial.number} finished in {elapsed_time:.2f} seconds.\")\n",
    "            self.start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = \"/data3/lsf/Pein/Power-Prediction/data/\"\n",
    "file_name_common = 'farm_92'\n",
    "train_data_selected = pd.read_csv(data_dir + f\"train_{file_name_common}.csv\")\n",
    "test_data_selected = pd.read_csv(data_dir + f\"test_{file_name_common}.csv\")\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    col\n",
    "    for col in train_data_selected.columns\n",
    "    if col not in [\"time\", \"lead_hour\", \"power\"]\n",
    "]\n",
    "X_train = train_data_selected[features]\n",
    "y_train = train_data_selected[\"power\"]\n",
    "X_test = test_data_selected[features]\n",
    "y_test = test_data_selected[\"power\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (14592, 89), Shape of y_train: (14592,)\n",
      "Shape of X_test: (2880, 89), Shape of y_test: (2880,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}, Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}, Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' column to datetime\n",
    "train_data_selected[\"time\"] = pd.to_datetime(train_data_selected[\"time\"])\n",
    "test_data_selected[\"time\"] = pd.to_datetime(test_data_selected[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add time features\n",
    "def add_time_features(df):\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "    # Existing time features\n",
    "    df[\"hour\"] = df[\"time\"].dt.hour\n",
    "    df[\"quarter_hour\"] = df[\"time\"].dt.minute // 15\n",
    "\n",
    "    # New time features\n",
    "    df[\"day\"] = df[\"time\"].dt.day\n",
    "    df[\"day_in_week\"] = df[\"time\"].dt.weekday\n",
    "\n",
    "    # Sine and cosine transformations\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "\n",
    "    df[\"quarter_hour_sin\"] = np.sin(2 * np.pi * df[\"quarter_hour\"] / 4)\n",
    "    df[\"quarter_hour_cos\"] = np.cos(2 * np.pi * df[\"quarter_hour\"] / 4)\n",
    "\n",
    "    df[\"day_sin\"] = np.sin(2 * np.pi * df[\"day\"] / 31)\n",
    "    df[\"day_cos\"] = np.cos(2 * np.pi * df[\"day\"] / 31)\n",
    "\n",
    "    df[\"day_in_week_sin\"] = np.sin(2 * np.pi * df[\"day_in_week\"] / 7)\n",
    "    df[\"day_in_week_cos\"] = np.cos(2 * np.pi * df[\"day_in_week\"] / 7)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add time features to both train and test data\n",
    "train_data_selected = add_time_features(train_data_selected)\n",
    "test_data_selected = add_time_features(test_data_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features including the new time features\n",
    "time_features = [\n",
    "    \"hour\",\n",
    "    \"quarter_hour\",\n",
    "    \"day\",\n",
    "    \"day_in_week\",\n",
    "    \"hour_sin\",\n",
    "    \"hour_cos\",\n",
    "    \"quarter_hour_sin\",\n",
    "    \"quarter_hour_cos\",\n",
    "    \"day_sin\",\n",
    "    \"day_cos\",\n",
    "    \"day_in_week_sin\",\n",
    "    \"day_in_week_cos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = features  + time_features\n",
    "\n",
    "X_train = train_data_selected[all_features]\n",
    "X_test = test_data_selected[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    use_test_for_validation_flag=False,\n",
    "):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 80),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 50),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1500),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"num_threads\": 16,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    if use_test_for_validation_flag and X_test is not None and y_test is not None:\n",
    "        X_val_split, y_val_split = X_test, y_test\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val_split, y_val_split)],\n",
    "            eval_metric=\"rmse\",\n",
    "            callbacks=[early_stopping(stopping_rounds=15), log_evaluation(period=500)],\n",
    "        )\n",
    "        preds = model.predict(X_val_split)\n",
    "    else:\n",
    "        # Calculate the split index\n",
    "        split_index = int(0.8 * len(X_train))\n",
    "\n",
    "        # Split the data\n",
    "        X_train_split, X_val_split = X_train[:split_index], X_train[split_index:]\n",
    "        y_train_split, y_val_split = y_train[:split_index], y_train[split_index:]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_split,\n",
    "            y_train_split,\n",
    "            eval_set=[(X_val_split, y_val_split)],\n",
    "            eval_metric=\"rmse\",\n",
    "            callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=500)],\n",
    "        )\n",
    "        preds = model.predict(X_val_split)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = root_mean_squared_error(y_val_split, preds)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:18,239] A new study created in memory with name: no-name-2f35a737-4a6f-4d14-a18c-01581519b1c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:18,581] Trial 0 finished with value: 361.3208677782303 and parameters: {'num_leaves': 28, 'max_depth': 15, 'learning_rate': 0.16552636426472944, 'n_estimators': 808, 'min_child_samples': 43, 'subsample': 0.5659593422415234, 'colsample_bytree': 0.8550790981732623}. Best is trial 0 with value: 361.3208677782303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 361.321\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:18,991] Trial 1 finished with value: 359.613092031948 and parameters: {'num_leaves': 38, 'max_depth': 15, 'learning_rate': 0.17991063786833297, 'n_estimators': 1262, 'min_child_samples': 34, 'subsample': 0.7348078640655231, 'colsample_bytree': 0.8873377717742184}. Best is trial 1 with value: 359.613092031948.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's rmse: 359.613\n",
      "Trial 1 finished in 0.41 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:20,069] Trial 2 finished with value: 356.87173104820914 and parameters: {'num_leaves': 78, 'max_depth': 35, 'learning_rate': 0.04732641308299843, 'n_estimators': 743, 'min_child_samples': 35, 'subsample': 0.9579247897655769, 'colsample_bytree': 0.9623900013559523}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's rmse: 356.872\n",
      "Trial 2 finished in 1.08 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:20,599] Trial 3 finished with value: 366.9324462668337 and parameters: {'num_leaves': 37, 'max_depth': 46, 'learning_rate': 0.05289563007637222, 'n_estimators': 1236, 'min_child_samples': 40, 'subsample': 0.40207546941973255, 'colsample_bytree': 0.8197961282539361}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 366.932\n",
      "Trial 3 finished in 0.53 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:20,918] Trial 4 finished with value: 370.79632151867736 and parameters: {'num_leaves': 28, 'max_depth': 38, 'learning_rate': 0.14198272367539663, 'n_estimators': 725, 'min_child_samples': 29, 'subsample': 0.6467655723248791, 'colsample_bytree': 0.7785551502763874}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 370.796\n",
      "Trial 4 finished in 0.32 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:21,457] Trial 5 finished with value: 365.4959032882582 and parameters: {'num_leaves': 51, 'max_depth': 28, 'learning_rate': 0.1291341814606853, 'n_estimators': 1116, 'min_child_samples': 17, 'subsample': 0.8554255271337983, 'colsample_bytree': 0.93775375539685}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's rmse: 365.496\n",
      "Trial 5 finished in 0.54 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:21,683] Trial 6 finished with value: 362.48589452098787 and parameters: {'num_leaves': 15, 'max_depth': 17, 'learning_rate': 0.14715316058427122, 'n_estimators': 921, 'min_child_samples': 48, 'subsample': 0.8677863465068953, 'colsample_bytree': 0.54276995345514}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's rmse: 362.486\n",
      "Trial 6 finished in 0.23 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:22,751] Trial 7 finished with value: 358.84029197393596 and parameters: {'num_leaves': 74, 'max_depth': 16, 'learning_rate': 0.024895390419359835, 'n_estimators': 904, 'min_child_samples': 47, 'subsample': 0.3422377807076081, 'colsample_bytree': 0.6086988912903137}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's rmse: 358.84\n",
      "Trial 7 finished in 1.07 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:23,591] Trial 8 finished with value: 361.25546530029527 and parameters: {'num_leaves': 79, 'max_depth': 27, 'learning_rate': 0.12856457762844486, 'n_estimators': 822, 'min_child_samples': 26, 'subsample': 0.8110657023130203, 'colsample_bytree': 0.760711251561369}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's rmse: 361.255\n",
      "Trial 8 finished in 0.84 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:24,083] Trial 9 finished with value: 361.2347561573442 and parameters: {'num_leaves': 54, 'max_depth': 25, 'learning_rate': 0.10409986865436618, 'n_estimators': 815, 'min_child_samples': 10, 'subsample': 0.9760659033368986, 'colsample_bytree': 0.5115715465484687}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's rmse: 361.235\n",
      "Trial 9 finished in 0.49 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:25,039] Trial 10 finished with value: 366.36027000419364 and parameters: {'num_leaves': 65, 'max_depth': 39, 'learning_rate': 0.07618799560862825, 'n_estimators': 526, 'min_child_samples': 21, 'subsample': 0.9987157320287122, 'colsample_bytree': 0.9984890489739019}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's rmse: 366.36\n",
      "Trial 10 finished in 0.96 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:27,318] Trial 11 finished with value: 361.24143982179515 and parameters: {'num_leaves': 78, 'max_depth': 35, 'learning_rate': 0.010148711298342886, 'n_estimators': 581, 'min_child_samples': 50, 'subsample': 0.3151842235962813, 'colsample_bytree': 0.6404620338962632}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[379]\tvalid_0's rmse: 361.241\n",
      "Trial 11 finished in 2.28 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:28,198] Trial 12 finished with value: 364.7601132608837 and parameters: {'num_leaves': 66, 'max_depth': 10, 'learning_rate': 0.026796048340675734, 'n_estimators': 1031, 'min_child_samples': 36, 'subsample': 0.47017295454810515, 'colsample_bytree': 0.668670804362171}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's rmse: 364.76\n",
      "Trial 12 finished in 0.88 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:28,921] Trial 13 finished with value: 365.7372479396751 and parameters: {'num_leaves': 67, 'max_depth': 49, 'learning_rate': 0.06288610001069915, 'n_estimators': 1484, 'min_child_samples': 44, 'subsample': 0.5356358470365424, 'colsample_bytree': 0.6688190584592907}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's rmse: 365.737\n",
      "Trial 13 finished in 0.72 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:29,940] Trial 14 finished with value: 361.7573271822551 and parameters: {'num_leaves': 72, 'max_depth': 33, 'learning_rate': 0.034438031005016065, 'n_estimators': 667, 'min_child_samples': 36, 'subsample': 0.6678519476014424, 'colsample_bytree': 0.5967710437544302}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's rmse: 361.757\n",
      "Trial 14 finished in 1.02 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:30,591] Trial 15 finished with value: 373.7785457614279 and parameters: {'num_leaves': 58, 'max_depth': 21, 'learning_rate': 0.07812331654536908, 'n_estimators': 938, 'min_child_samples': 40, 'subsample': 0.3165122158726478, 'colsample_bytree': 0.7359132164140239}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's rmse: 373.779\n",
      "Trial 15 finished in 0.65 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:31,378] Trial 16 finished with value: 363.6063331439195 and parameters: {'num_leaves': 79, 'max_depth': 43, 'learning_rate': 0.09583362877288779, 'n_estimators': 1099, 'min_child_samples': 31, 'subsample': 0.44550292169764394, 'colsample_bytree': 0.973360127213602}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's rmse: 363.606\n",
      "Trial 16 finished in 0.79 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:32,414] Trial 17 finished with value: 361.17055472217567 and parameters: {'num_leaves': 59, 'max_depth': 21, 'learning_rate': 0.04362733997772725, 'n_estimators': 627, 'min_child_samples': 46, 'subsample': 0.761216013076758, 'colsample_bytree': 0.594786523240673}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's rmse: 361.171\n",
      "Trial 17 finished in 1.04 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:34,214] Trial 18 finished with value: 360.0855169479112 and parameters: {'num_leaves': 72, 'max_depth': 32, 'learning_rate': 0.017184101658983434, 'n_estimators': 733, 'min_child_samples': 23, 'subsample': 0.9146115744604509, 'colsample_bytree': 0.7290841853016669}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 360.086\n",
      "Trial 18 finished in 1.80 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:34,865] Trial 19 finished with value: 358.8624453204303 and parameters: {'num_leaves': 45, 'max_depth': 11, 'learning_rate': 0.06785831364793997, 'n_estimators': 898, 'min_child_samples': 40, 'subsample': 0.5858787994783083, 'colsample_bytree': 0.8914022995045465}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's rmse: 358.862\n",
      "Trial 19 finished in 0.65 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:35,829] Trial 20 finished with value: 363.6627134308896 and parameters: {'num_leaves': 73, 'max_depth': 23, 'learning_rate': 0.03852940201584988, 'n_estimators': 1227, 'min_child_samples': 32, 'subsample': 0.3905400180261214, 'colsample_bytree': 0.691372029914296}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's rmse: 363.663\n",
      "Trial 20 finished in 0.96 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:36,163] Trial 21 finished with value: 357.3230002361739 and parameters: {'num_leaves': 14, 'max_depth': 11, 'learning_rate': 0.06782396022375077, 'n_estimators': 904, 'min_child_samples': 40, 'subsample': 0.5736581520422552, 'colsample_bytree': 0.9148208843310814}. Best is trial 2 with value: 356.87173104820914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's rmse: 357.323\n",
      "Trial 21 finished in 0.33 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:36,529] Trial 22 finished with value: 344.1361996159678 and parameters: {'num_leaves': 15, 'max_depth': 18, 'learning_rate': 0.08952512928506817, 'n_estimators': 996, 'min_child_samples': 38, 'subsample': 0.4880352084515938, 'colsample_bytree': 0.9424165955548771}. Best is trial 22 with value: 344.1361996159678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's rmse: 344.136\n",
      "Trial 22 finished in 0.37 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:36,841] Trial 23 finished with value: 363.10431238597226 and parameters: {'num_leaves': 12, 'max_depth': 10, 'learning_rate': 0.08979721961102416, 'n_estimators': 1005, 'min_child_samples': 39, 'subsample': 0.49958607176488834, 'colsample_bytree': 0.9501055289758689}. Best is trial 22 with value: 344.1361996159678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's rmse: 363.104\n",
      "Trial 23 finished in 0.31 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:37,204] Trial 24 finished with value: 351.50682240543796 and parameters: {'num_leaves': 20, 'max_depth': 19, 'learning_rate': 0.1148027897945388, 'n_estimators': 1114, 'min_child_samples': 36, 'subsample': 0.6317099035278214, 'colsample_bytree': 0.9172099517897333}. Best is trial 22 with value: 344.1361996159678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 351.507\n",
      "Trial 24 finished in 0.36 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:37,612] Trial 25 finished with value: 341.7043715533523 and parameters: {'num_leaves': 21, 'max_depth': 21, 'learning_rate': 0.1170591971593041, 'n_estimators': 1350, 'min_child_samples': 35, 'subsample': 0.6506927490892368, 'colsample_bytree': 0.8103864882602075}. Best is trial 25 with value: 341.7043715533523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's rmse: 341.704\n",
      "Trial 25 finished in 0.41 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:38,076] Trial 26 finished with value: 358.3933191239015 and parameters: {'num_leaves': 21, 'max_depth': 19, 'learning_rate': 0.1168419190905329, 'n_estimators': 1406, 'min_child_samples': 28, 'subsample': 0.6479681696648903, 'colsample_bytree': 0.8238819309641573}. Best is trial 25 with value: 341.7043715533523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's rmse: 358.393\n",
      "Trial 26 finished in 0.46 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:38,407] Trial 27 finished with value: 354.57101922117715 and parameters: {'num_leaves': 21, 'max_depth': 26, 'learning_rate': 0.11862924721168484, 'n_estimators': 1342, 'min_child_samples': 33, 'subsample': 0.7046799257757459, 'colsample_bytree': 0.8491064004527067}. Best is trial 25 with value: 341.7043715533523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 354.571\n",
      "Trial 27 finished in 0.33 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:38,775] Trial 28 finished with value: 350.73729426434807 and parameters: {'num_leaves': 20, 'max_depth': 19, 'learning_rate': 0.09281879787338747, 'n_estimators': 1155, 'min_child_samples': 37, 'subsample': 0.6122687197116748, 'colsample_bytree': 0.7966872430791309}. Best is trial 25 with value: 341.7043715533523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's rmse: 350.737\n",
      "Trial 28 finished in 0.37 seconds.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22878\n",
      "[LightGBM] [Info] Number of data points in the train set: 11673, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 564.183276\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-07 14:20:39,167] Trial 29 finished with value: 370.86154589971875 and parameters: {'num_leaves': 28, 'max_depth': 13, 'learning_rate': 0.1614890618665271, 'n_estimators': 1323, 'min_child_samples': 43, 'subsample': 0.5365135472026565, 'colsample_bytree': 0.7897437546217961}. Best is trial 25 with value: 341.7043715533523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's rmse: 370.862\n",
      "Trial 29 finished in 0.39 seconds.\n",
      "Best parameters found:  {'num_leaves': 21, 'max_depth': 21, 'learning_rate': 0.1170591971593041, 'n_estimators': 1350, 'min_child_samples': 35, 'subsample': 0.6506927490892368, 'colsample_bytree': 0.8103864882602075}\n"
     ]
    }
   ],
   "source": [
    "# Create the study and optimize\n",
    "use_test_for_validation_flag = False\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        use_test_for_validation_flag=use_test_for_validation_flag,\n",
    "    ),\n",
    "    n_trials=30,\n",
    "    callbacks=[TimingCallback()],\n",
    ")\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {\n",
    "#     \"num_leaves\": 70,\n",
    "#     \"max_depth\": 36,\n",
    "#     \"learning_rate\": 0.09304350950671668,\n",
    "#     \"n_estimators\": 1158,\n",
    "#     \"min_child_samples\": 18,\n",
    "#     \"subsample\": 0.579731306036922,\n",
    "#     \"colsample_bytree\": 0.8511910376678277,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'num_leaves': 21, 'max_depth': 21, 'learning_rate': 0.1170591971593041, 'n_estimators': 1350, 'min_child_samples': 35, 'subsample': 0.6506927490892368, 'colsample_bytree': 0.8103864882602075}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 22879\n",
      "[LightGBM] [Info] Number of data points in the train set: 14592, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score 540.706096\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best_params)\n",
    "best_params[\"num_threads\"] = 16\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = LGBMRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to hold the features and their importances\n",
    "importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_train.columns, \"Importance\": feature_importances}\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set: 335.8639\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE on the test set: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save important_features to csv file\n",
    "if use_test_for_validation_flag:\n",
    "    importance_df.to_csv(\"farm_important_features_use_test_for_validation.csv\", index=False)\n",
    "else:\n",
    "    importance_df.to_csv(\"farm_important_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for feature importance\n",
    "importance_threshold = 54\n",
    "\n",
    "# Select features with importance greater than or equal to the threshold\n",
    "selected_features = importance_df[importance_df[\"Importance\"] >= importance_threshold][\n",
    "    \"Feature\"\n",
    "].tolist()\n",
    "\n",
    "# Separate selected features into original input features and time features\n",
    "selected_input_features = [\n",
    "    feature for feature in selected_features if feature not in time_features\n",
    "]\n",
    "selected_time_features = [\n",
    "    feature for feature in selected_features if feature in time_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_data_final: (14592, 98)\n",
      "Shape of test_data_final: (2880, 98)\n",
      "Selected input features: ['mgws', 'lgws', 'altitude', 'trpp', 'azimuth', 'deg0l', 'mudlp', 'blh', 'viwvn', 'kx', 'degm10l', 'mcc', 'gwd', 'p3020', 'totalx', 'lcc', 'mld', 'tcsw', 'sund', 'vimd', 'capes', 'bld', 'tcc', 'fg10', 'ishf', 'lspf', 'viwve', 'ewss', 'litoti', 'flsr', 'nsss', 'ilspf', 'str', 'u100', 'cape', 'hcc', 'u200', 'mlcape100', 'ws10', 'hwbt0', 'u10', 'ws200', 'msl', 'ws100', 'i10fg', 'ttrc', 'dsrp', 'mlcape50', 'u10n', 'slhf', 'hwbt1', 'ttr', 'mucape', 'fdir', 'cdir', 'strc', 'sshf', 'v200', 'v10n', 'ssrd', 'strd', 'd2m', 'v10', 'tcw', 'par', 'v100', 'uvb', 'tsr', 'tisr', 'sp', 'parcs', 't2m', 'mx2t', 'ssrc', 'tsrc', 'ssr', 'tcwv', 'mn2t', 'ssrdc', 'sst', 'skt', 'strdc', 'lblt', 'stl1']\n",
      "Train columns : Index(['time', 'mgws', 'lgws', 'altitude', 'trpp', 'azimuth', 'deg0l', 'mudlp',\n",
      "       'blh', 'viwvn', 'kx', 'degm10l', 'mcc', 'gwd', 'p3020', 'totalx', 'lcc',\n",
      "       'mld', 'tcsw', 'sund', 'vimd', 'capes', 'bld', 'tcc', 'fg10', 'ishf',\n",
      "       'lspf', 'viwve', 'ewss', 'litoti', 'flsr', 'nsss', 'ilspf', 'str',\n",
      "       'u100', 'cape', 'hcc', 'u200', 'mlcape100', 'ws10', 'hwbt0', 'u10',\n",
      "       'ws200', 'msl', 'ws100', 'i10fg', 'ttrc', 'dsrp', 'mlcape50', 'u10n',\n",
      "       'slhf', 'hwbt1', 'ttr', 'mucape', 'fdir', 'cdir', 'strc', 'sshf',\n",
      "       'v200', 'v10n', 'ssrd', 'strd', 'd2m', 'v10', 'tcw', 'par', 'v100',\n",
      "       'uvb', 'tsr', 'tisr', 'sp', 'parcs', 't2m', 'mx2t', 'ssrc', 'tsrc',\n",
      "       'ssr', 'tcwv', 'mn2t', 'ssrdc', 'sst', 'skt', 'strdc', 'lblt', 'stl1',\n",
      "       'power', 'hour', 'quarter_hour', 'day', 'day_in_week', 'hour_sin',\n",
      "       'hour_cos', 'quarter_hour_sin', 'quarter_hour_cos', 'day_sin',\n",
      "       'day_cos', 'day_in_week_sin', 'day_in_week_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine the filtered features with the power column and time features\n",
    "train_data_final = pd.concat(\n",
    "    [\n",
    "        train_data_selected[\"time\"],\n",
    "        X_train[selected_input_features],\n",
    "        train_data_selected[\"power\"],\n",
    "        train_data_selected[time_features],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "test_data_final = pd.concat(\n",
    "    [\n",
    "        test_data_selected[\"time\"],\n",
    "        X_test[selected_input_features],\n",
    "        test_data_selected[\"power\"],\n",
    "        test_data_selected[time_features],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Ensure the final order of columns\n",
    "final_columns = [\"time\"] + selected_input_features + [\"power\"] + time_features\n",
    "train_data_final = train_data_final[final_columns]\n",
    "test_data_final = test_data_final[final_columns]\n",
    "\n",
    "# Display the new shapes of train_data_final and test_data_final\n",
    "print(\"Shape of train_data_final:\", train_data_final.shape)\n",
    "print(\"Shape of test_data_final:\", test_data_final.shape)\n",
    "print(\"Selected input features:\", selected_input_features)\n",
    "print(f\"Train columns : {train_data_final.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final datasets saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "# Save the final datasets to CSV\n",
    "file_name_common = 'farm_98_withTime'\n",
    "train_data_final.to_csv(data_dir + f\"train_{file_name_common}.csv\", index=False)\n",
    "test_data_final.to_csv(data_dir + f\"test_{file_name_common}.csv\", index=False)\n",
    "print(\"Final datasets saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pein_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
