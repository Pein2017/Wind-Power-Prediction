2024-08-09 13:22:54,213 Residual shape: torch.Size([10, 102, 24])
2024-08-09 13:22:54,213 x.shape before conv1 torch.Size([10, 32, 51])
2024-08-09 13:22:54,216 x.shape after conv1 torch.Size([10, 102, 28]) and before conv2
2024-08-09 13:22:54,217 x.shape after conv2 torch.Size([10, 102, 24]) and before attention or MLP
2024-08-09 13:22:54,219 x.shape after attention or MLP torch.Size([10, 102, 24]) and before residual connection
2024-08-09 13:24:18,816 x.shape before block [0]: torch.Size([10, 32, 51])
2024-08-09 13:24:18,820 Residual shape: torch.Size([10, 102, 24])
2024-08-09 13:24:18,821 x.shape before conv1 torch.Size([10, 32, 51])
2024-08-09 13:24:18,823 x.shape after conv1 torch.Size([10, 102, 28]) and before conv2
2024-08-09 13:24:18,824 x.shape after conv2 torch.Size([10, 102, 24]) and before attention or MLP
2024-08-09 13:24:18,826 x.shape after attention or MLP torch.Size([10, 102, 24]) and before residual connection
2024-08-09 13:24:18,826 x.shape before block [1]: torch.Size([10, 24, 102])
2024-08-09 14:23:34,916 self.blocks is ModuleList(
  (0): Conv1d(51, 52, kernel_size=(1,), stride=(1,))
  (1): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(52, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(104, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(52, 104, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=104, out_features=208, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=208, out_features=104, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (2): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(104, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(208, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(104, 208, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=208, out_features=416, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=416, out_features=208, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (3): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(208, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(416, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(208, 416, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=416, out_features=832, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=832, out_features=416, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
2024-08-09 14:24:31,411 self.blocks is ModuleList(
  (0): Conv1d(51, 52, kernel_size=(1,), stride=(1,))
  (1): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(52, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(104, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(52, 104, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=104, out_features=208, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=208, out_features=104, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (2): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(104, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(208, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(104, 208, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=208, out_features=416, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=416, out_features=208, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (3): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(208, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(416, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(208, 416, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=416, out_features=832, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=832, out_features=416, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
2024-08-09 14:26:10,715 self.blocks is ModuleList(
  (0): Conv1d(51, 52, kernel_size=(1,), stride=(1,))
  (1): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(52, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(104, 104, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(52, 104, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=104, out_features=208, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=208, out_features=104, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (2): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(104, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(208, 208, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(104, 208, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=208, out_features=416, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=416, out_features=208, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (3): EnhancedBlock(
    (conv1): ConvLayer(
      (conv): Conv1d(208, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (conv2): ConvLayer(
      (conv): Conv1d(416, 416, kernel_size=(5,), stride=(1,))
      (activation_type): GELU(approximate='none')
    )
    (residual_conv): Conv1d(208, 416, kernel_size=(1,), stride=(1,))
    (residual_pool): AvgPool1d(kernel_size=(9,), stride=(1,), padding=(0,))
    (norm1): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (norm2): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer): Sequential(
      (0): Linear(in_features=416, out_features=832, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=832, out_features=416, bias=True)
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
2024-08-09 16:18:17,578 original_input_dim: 51, adjusted_input_dim: 55
2024-08-09 16:18:18,413 original_input_dim: 50, adjusted_input_dim: 56
2024-08-09 16:18:22,680 original_input_dim: 53, adjusted_input_dim: 54
2024-08-09 16:18:22,713 original_input_dim: 64, adjusted_input_dim: 64
2024-08-09 16:18:22,797 original_input_dim: 55, adjusted_input_dim: 56
2024-08-09 16:18:22,833 original_input_dim: 60, adjusted_input_dim: 60
2024-08-09 16:18:22,843 original_input_dim: 49, adjusted_input_dim: 51
2024-08-09 16:18:46,775 original_input_dim: 51, adjusted_input_dim: 55
2024-08-09 16:18:47,583 original_input_dim: 50, adjusted_input_dim: 56
2024-08-09 16:18:51,815 original_input_dim: 53, adjusted_input_dim: 54
2024-08-09 16:18:51,850 original_input_dim: 64, adjusted_input_dim: 64
2024-08-09 16:18:51,934 original_input_dim: 55, adjusted_input_dim: 56
2024-08-09 16:18:51,970 original_input_dim: 60, adjusted_input_dim: 60
2024-08-09 16:18:51,980 original_input_dim: 49, adjusted_input_dim: 51
2024-08-09 16:18:51,990 original_input_dim: 62, adjusted_input_dim: 65
